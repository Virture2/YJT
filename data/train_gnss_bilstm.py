import sys
import os
import torch
import math
from tqdm import tqdm
import torch.nn as nn
from torch.utils.data import DataLoader

# ===== è·¯å¾„å¯¼å…¥ =====
sys.path.insert(0, '../')
from src.data.components.new_KITTI_dataset import KITTI
from src.utils import new_custom_transform
from src.models.components.new_vsvio import Encoder

# ===== å‚æ•°è®¾ç½® =====
class ObjFromDict:
    def __init__(self, dictionary):
        for k, v in dictionary.items():
            setattr(self, k, v)

params = {
    "img_w": 512,
    "img_h": 256,
    "v_f_len": 512,
    "i_f_len": 256,
    "g_f_len": 128,
    "imu_dropout": 0.1,
    "seq_len": 11
}
params = ObjFromDict(params)

# ===== GNSS-only æ¨¡å‹ç»“æ„ =====
class GNSSPoseNet(nn.Module):
    def __init__(self, encoder: Encoder, pose_dim=6):
        super().__init__()
        self.gnss_encoder = encoder.gnss_encoder  # ä½¿ç”¨ç°æœ‰çš„ GNSS encoder åˆ†æ”¯
        self.pose_head = nn.Sequential(
            nn.Linear(params.g_f_len, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, pose_dim)
        )

    def forward(self, gnss):  # gnss: (B, T, 3)
        feat_g = self.gnss_encoder(gnss)  # (B, T, 128)
        return self.pose_head(feat_g)     # (B, T, 6)

# ===== æ•°æ®åŠ è½½ =====
transform_train = new_custom_transform.Compose([
    new_custom_transform.ToTensor(),
    new_custom_transform.Resize((256, 512))
])

dataset = KITTI(
    "kitti_data",  # è¯·æ›¿æ¢æˆä½ çš„KITTIæ•°æ®æ ¹ç›®å½•
    train_seqs=['00', '01', '02', '04', '06', '09'],
    transform=transform_train,
    sequence_length=11
)
loader = DataLoader(dataset, batch_size=2, shuffle=True)

# ===== åˆå§‹åŒ–æ¨¡å‹ =====
full_encoder = Encoder(params)
model = GNSSPoseNet(full_encoder).to("cuda")

# ===== ä¼˜åŒ–å™¨ & æŸå¤±å‡½æ•° =====
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
criterion = nn.L1Loss()

# ===== è®­ç»ƒè®¾ç½® =====
checkpoint_dir = "E:/VITF/pretrained_models/gnss_stage1"
os.makedirs(checkpoint_dir, exist_ok=True)

start_epoch = 43
num_epochs = 27

# ===== æ³¨é‡Šæ–­ç‚¹æ¢å¤éƒ¨åˆ† =====
resume_path = os.path.join(checkpoint_dir, "stage1_epoch_latest.pth")
if os.path.exists(resume_path):
    print(f"ğŸ”„ æ¢å¤è®­ç»ƒï¼šåŠ è½½ {resume_path}")
    checkpoint = torch.load(resume_path)
    model.load_state_dict(checkpoint['model_state_dict'])
    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
    start_epoch = checkpoint['epoch']
else:
    print("ğŸ†• ä»å¤´å¼€å§‹è®­ç»ƒ GNSS encoder + MLP head")

# ===== æ­£å¼è®­ç»ƒ =====
model.train()
for epoch in range(start_epoch, start_epoch + num_epochs):
    epoch_loss = 0.0

    for i, ((imgs, imus, gnss, rot, w), gts) in enumerate(tqdm(loader)):
        gnss = gnss.to("cuda").float()  # (B, T, 3)
        gts = gts.to("cuda").float()    # (B, T, 6)

        optimizer.zero_grad()
        pred_pose = model(gnss)         # (B, T, 6)
        loss = criterion(pred_pose, gts)
        loss.backward()
        optimizer.step()

        epoch_loss += loss.item()

    avg_loss = epoch_loss / (i + 1)
    print(f"[Stage 1][Epoch {epoch+1}] Avg Loss: {avg_loss:.6f}")

    # ===== ä¿å­˜å½“å‰æ¨¡å‹ï¼ˆæ–­ç‚¹ç»­è®­ï¼‰=====
    torch.save({
        'epoch': epoch + 1,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'loss': avg_loss
    }, os.path.join(checkpoint_dir, "stage1_epoch_latest.pth"))

# ===== æœ€ç»ˆä¿å­˜ GNSS encoder æƒé‡ï¼ˆå¸¦å‰ç¼€ï¼‰=====
gnss_state_dict = model.gnss_encoder.state_dict()
prefixed_state_dict = {}
prefix = "Feature_net.gnss_encoder."
for k, v in gnss_state_dict.items():
    new_key = prefix + k
    prefixed_state_dict[new_key] = v

torch.save(prefixed_state_dict, os.path.join(checkpoint_dir, "gnss_encoder_stage1_final.pth"))
print("âœ… è®­ç»ƒå®Œæˆï¼Œå¸¦å‰ç¼€çš„ GNSS encoder æƒé‡å·²ä¿å­˜ï¼šgnss_encoder_stage1_final.pth")


